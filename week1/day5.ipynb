{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98030af-fcd1-4d63-a36e-38ba053498fa",
   "metadata": {},
   "source": [
    "# A full business solution\n",
    "\n",
    "## Now we will take our project from Day 1 to the next level\n",
    "\n",
    "### BUSINESS CHALLENGE:\n",
    "\n",
    "Create a product that builds a Brochure for a company to be used for prospective clients, investors and potential recruits.\n",
    "\n",
    "We will be provided a company name and their primary website.\n",
    "\n",
    "See the end of this notebook for examples of real-world business applications.\n",
    "\n",
    "And remember: I'm always available if you have problems or ideas! Please do reach out."
   ]
  },
  {
   "cell_type": "code",
   "id": "d5b08506-dc8b-4443-9201-5f1848161363",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:37:41.462030Z",
     "start_time": "2026-01-16T04:37:41.447614Z"
    }
   },
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from scraper import fetch_website_links, fetch_website_contents\n",
    "from openai import OpenAI\n",
    "\n",
    "from week1.solutions.day1_with_ollama import messages"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "fc5d8880-f2ee-4c06-af16-ecbc0262af61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:39:40.413497Z",
     "start_time": "2026-01-16T04:39:40.396538Z"
    }
   },
   "source": [
    "# Initialize and constants\n",
    "\n",
    "# load_dotenv(override=True)\n",
    "# api_key = os.getenv('OPENAI_API_KEY')\n",
    "#\n",
    "# if not api_key:\n",
    "#     print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "# elif not api_key.startswith(\"sk-proj-\") and api_key != 'ollama':\n",
    "#     print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "# else:\n",
    "#     print(\"API key found and looks good so far!\")\n",
    "\n",
    "# I'm using Ollama for this notebook and running a local Llama 3.2 model\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "MODEL = 'llama3.2:latest'\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "e30d8128-933b-44cc-81c8-ab4c9d86589a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:14:31.229371Z",
     "start_time": "2026-01-16T04:14:29.903570Z"
    }
   },
   "source": [
    "links = fetch_website_links(\"https://edwarddonner.com\")\n",
    "links"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/curriculum/',\n",
       " 'https://edwarddonner.com/proficient/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://news.ycombinator.com',\n",
       " 'https://nebula.io/?utm_source=ed&utm_medium=referral',\n",
       " 'https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html',\n",
       " 'https://edwarddonner.com/curriculum/',\n",
       " 'https://edwarddonner.com/2026/01/04/ai-builder-with-n8n-create-agents-and-voice-agents/',\n",
       " 'https://edwarddonner.com/2026/01/04/ai-builder-with-n8n-create-agents-and-voice-agents/',\n",
       " 'https://edwarddonner.com/2025/11/11/ai-live-event/',\n",
       " 'https://edwarddonner.com/2025/11/11/ai-live-event/',\n",
       " 'https://edwarddonner.com/2025/09/15/ai-in-production-gen-ai-and-agentic-ai-on-aws-at-scale/',\n",
       " 'https://edwarddonner.com/2025/09/15/ai-in-production-gen-ai-and-agentic-ai-on-aws-at-scale/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/curriculum/',\n",
       " 'https://edwarddonner.com/proficient/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'mailto:hello@mygroovydomain.com',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://twitter.com/edwarddonner',\n",
       " 'https://www.facebook.com/edward.donner.52']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "1771af9c-717a-4fca-bbbe-8a95893312c3",
   "metadata": {},
   "source": [
    "## First step: Have GPT-5-nano figure out which links are relevant\n",
    "\n",
    "### Use a call to gpt-5-nano to read the links on a webpage, and respond in structured JSON.  \n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".  \n",
    "We will use \"one shot prompting\" in which we provide an example of how it should respond in the prompt.\n",
    "\n",
    "This is an excellent use case for an LLM, because it requires nuanced understanding. Imagine trying to code this without LLMs by parsing and analyzing the webpage - it would be very hard!\n",
    "\n",
    "Sidenote: there is a more advanced technique called \"Structured Outputs\" in which we require the model to respond according to a spec. We cover this technique in Week 8 during our autonomous Agentic AI project."
   ]
  },
  {
   "cell_type": "code",
   "id": "6957b079-0d96-45f7-a26a-3487510e9b35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:37:48.771176Z",
     "start_time": "2026-01-16T04:37:48.763226Z"
    }
   },
   "source": [
    "link_system_prompt = \"\"\"\n",
    "You are provided with a list of links found on a webpage.\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company,\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
    "You should respond in JSON as in this example:\n",
    "\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "8e1f601b-2eaf-499d-b6b8-c99050c9d6b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:37:50.844691Z",
     "start_time": "2026-01-16T04:37:50.826168Z"
    }
   },
   "source": [
    "def get_links_user_prompt(url):\n",
    "    user_prompt = f\"\"\"\n",
    "Here is the list of links on the website {url} -\n",
    "Please decide which of these are relevant web links for a brochure about the company, \n",
    "respond with the full https URL in JSON format.\n",
    "Do not include Terms of Service, Privacy, email links.\n",
    "\n",
    "Links (some might be relative links):\n",
    "\n",
    "\"\"\"\n",
    "    links = fetch_website_links(url)\n",
    "    user_prompt += \"\\n\".join(links)\n",
    "    return user_prompt"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "6bcbfa78-6395-4685-b92c-22d592050fd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:37:57.234791Z",
     "start_time": "2026-01-16T04:37:56.972257Z"
    }
   },
   "source": [
    "print(get_links_user_prompt(\"https://edwarddonner.com\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is the list of links on the website https://edwarddonner.com -\n",
      "Please decide which of these are relevant web links for a brochure about the company, \n",
      "respond with the full https URL in JSON format.\n",
      "Do not include Terms of Service, Privacy, email links.\n",
      "\n",
      "Links (some might be relative links):\n",
      "\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/curriculum/\n",
      "https://edwarddonner.com/proficient/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "https://edwarddonner.com/\n",
      "https://news.ycombinator.com\n",
      "https://nebula.io/?utm_source=ed&utm_medium=referral\n",
      "https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html\n",
      "https://edwarddonner.com/curriculum/\n",
      "https://edwarddonner.com/2026/01/04/ai-builder-with-n8n-create-agents-and-voice-agents/\n",
      "https://edwarddonner.com/2026/01/04/ai-builder-with-n8n-create-agents-and-voice-agents/\n",
      "https://edwarddonner.com/2025/11/11/ai-live-event/\n",
      "https://edwarddonner.com/2025/11/11/ai-live-event/\n",
      "https://edwarddonner.com/2025/09/15/ai-in-production-gen-ai-and-agentic-ai-on-aws-at-scale/\n",
      "https://edwarddonner.com/2025/09/15/ai-in-production-gen-ai-and-agentic-ai-on-aws-at-scale/\n",
      "https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/\n",
      "https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/curriculum/\n",
      "https://edwarddonner.com/proficient/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "mailto:hello@mygroovydomain.com\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://twitter.com/edwarddonner\n",
      "https://www.facebook.com/edward.donner.52\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "effeb95f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:39:45.373694Z",
     "start_time": "2026-01-16T04:39:45.361285Z"
    }
   },
   "source": [
    "def select_relevant_links(url):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\n",
    "    ]\n",
    "\n",
    "    response = ollama.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    links = json.loads(result)\n",
    "    return links\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "490de841",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "2d5b1ded",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:40:08.538302Z",
     "start_time": "2026-01-16T04:39:48.150100Z"
    }
   },
   "source": "select_relevant_links(\"https://edwarddonner.com\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'company page', 'url': 'https://edwarddonner.com/'},\n",
       "  {'type': 'About page (personal)',\n",
       "   'url': 'https://edwarddonner.com/about-me-and-about-nebula/'},\n",
       "  {'type': 'Company page',\n",
       "   'url': 'https://nebula.io/?utm_source=ed&utm_medium=referral'},\n",
       "  {'type': 'LinkedIn profile', 'url': 'https://www.linkedin.com/in/eddonner/'},\n",
       "  {'type': 'Twitter profile', 'url': 'https://twitter.com/edwarddonner'}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b84c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26709d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "id": "a29aca19-ca13-471c-a4b4-5abbfa813f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:40:32.928454Z",
     "start_time": "2026-01-16T04:40:32.919695Z"
    }
   },
   "source": [
    "def select_relevant_links(url):\n",
    "    print(f\"Selecting relevant links for {url} by calling {MODEL}\")\n",
    "    response = ollama.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    links = json.loads(result)\n",
    "    print(f\"Found {len(links['links'])} relevant links\")\n",
    "    return links"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "74a827a0-2782-4ae5-b210-4a242a8b4cc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:41:14.368551Z",
     "start_time": "2026-01-16T04:40:35.787746Z"
    }
   },
   "source": [
    "select_relevant_links(\"https://edwarddonner.com\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting relevant links for https://edwarddonner.com by calling llama3.2:latest\n",
      "Found 6 relevant links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'home page', 'url': 'https://edwarddonner.com/'},\n",
       "  {'type': 'About page',\n",
       "   'url': 'https://edwarddonner.com/about-me-and-about-nebula/'},\n",
       "  {'type': 'Companies/nebula.io/',\n",
       "   'url': 'https://nebula.io/?utm_source=ed&utm_medium=referral'},\n",
       "  {'type': 'Careers/Jobs', 'url': None},\n",
       "  {'type': 'Blog/Posts', 'url': 'https://edwarddonner.com/posts/'},\n",
       "  {'type': 'LinkedIn Profile',\n",
       "   'url': 'https://www.linkedin.com/in/eddonner/',\n",
       "   \"#{redir:edwarddonnerlinkedin} #<#redir link> - {redir url}  ^{redir text} ^{redir attrtext} ^redir > ^\\x1b[31;1m{redir attr:facebook} \\x1bfound in: ^\\n ^\\x1b[32;1m{redir attr:twitter} \\x1bfound in: ^\\n ^\\x1b[34;1m{redir attr:text} \\x1bfound in: ^\\r?\\n\\rÂ· #<#redir link>- {\\redir:facebook text}\\n\\n^{\\newurl 'edwarddonnerlinkedinprofile'> ^\\x1b[36;1m# {redirattr:linkedin attrtext} \\x1bfound in: ^}\\x1b[0m\": {}}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d583e2-dcc4-40cc-9b28-1e8dbf402924",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_relevant_links(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74128e-dfb6-47ec-9549-288b621c838c",
   "metadata": {},
   "source": [
    "## Second step: make the brochure!\n",
    "\n",
    "Assemble all the details into another prompt to GPT-5-nano"
   ]
  },
  {
   "cell_type": "code",
   "id": "85a5b6e2-e7ef-44a9-bc7f-59ede71037b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:41:25.013397Z",
     "start_time": "2026-01-16T04:41:25.005938Z"
    }
   },
   "source": [
    "def fetch_page_and_all_relevant_links(url):\n",
    "    contents = fetch_website_contents(url)\n",
    "    relevant_links = select_relevant_links(url)\n",
    "    result = f\"## Landing Page:\\n\\n{contents}\\n## Relevant Links:\\n\"\n",
    "    for link in relevant_links['links']:\n",
    "        result += f\"\\n\\n### Link: {link['type']}\\n\"\n",
    "        result += fetch_website_contents(link[\"url\"])\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "5099bd14-076d-4745-baf3-dac08d8e5ab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:41:43.462533Z",
     "start_time": "2026-01-16T04:41:29.752029Z"
    }
   },
   "source": [
    "print(fetch_page_and_all_relevant_links(\"https://huggingface.co\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting relevant links for https://huggingface.co by calling llama3.2:latest\n",
      "Found 4 relevant links\n",
      "## Landing Page:\n",
      "\n",
      "Hugging Face â€“ The AI community building the future.\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 2M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "zai-org/GLM-Image\n",
      "Updated\n",
      "about 19 hours ago\n",
      "â€¢\n",
      "2.44k\n",
      "â€¢\n",
      "704\n",
      "fal/Qwen-Image-Edit-2511-Multiple-Angles-LoRA\n",
      "Updated\n",
      "8 days ago\n",
      "â€¢\n",
      "44.1k\n",
      "â€¢\n",
      "686\n",
      "Lightricks/LTX-2\n",
      "Updated\n",
      "1 day ago\n",
      "â€¢\n",
      "1.19M\n",
      "â€¢\n",
      "1.05k\n",
      "openbmb/AgentCPM-Explore\n",
      "Updated\n",
      "2 days ago\n",
      "â€¢\n",
      "315\n",
      "â€¢\n",
      "293\n",
      "Kijai/LTXV2_comfy\n",
      "Updated\n",
      "1 day ago\n",
      "â€¢\n",
      "41.1k\n",
      "â€¢\n",
      "283\n",
      "Browse 2M+ models\n",
      "Spaces\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "Featured\n",
      "798\n",
      "Qwen Image Multiple Angles 3D Camera\n",
      "ðŸŽ¥\n",
      "798\n",
      "Adjust camera angles in images using 3D controls or sliders\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "1.48k\n",
      "Z Image Turbo\n",
      "ðŸ–¼\n",
      "1.48k\n",
      "Generate stunning images from text descriptions in seconds\n",
      "Running\n",
      "Featured\n",
      "4.21k\n",
      "Wan2.2 Animate\n",
      "ðŸ‘\n",
      "4.21k\n",
      "Wan2.2 Animate\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "Featured\n",
      "395\n",
      "Qwen-Image-Edit-2511-LoRAs-Fast\n",
      "ðŸŽƒ\n",
      "395\n",
      "Demo of the Collection of Qwen Image Edit LoRAs\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "Featured\n",
      "1.83k\n",
      "Qwen Image Edit Camera Control\n",
      "ðŸŽ¬\n",
      "1.83k\n",
      "Fast 4 step inference with Qwen Image Edit 2509\n",
      "Browse 1M+ applications\n",
      "Datasets\n",
      "HuggingFaceFW/finetranslations\n",
      "Updated\n",
      "6 days ago\n",
      "â€¢\n",
      "14k\n",
      "â€¢\n",
      "204\n",
      "MiniMaxAI/OctoCodingBench\n",
      "Updated\n",
      "3 days ago\n",
      "â€¢\n",
      "2.64k\n",
      "â€¢\n",
      "183\n",
      "Alibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b\n",
      "Updated\n",
      "about 22 hours ago\n",
      "â€¢\n",
      "667\n",
      "â€¢\n",
      "113\n",
      "xiuhuywh/DRIM-VisualReasonHard\n",
      "Updated\n",
      "7 days ago\n",
      "â€¢\n",
      "1.95k\n",
      "â€¢\n",
      "127\n",
      "miromind-ai/MiroVerse-v0.1\n",
      "Updated\n",
      "about 3 hours ago\n",
      "â€¢\n",
      "810\n",
      "â€¢\n",
      "204\n",
      "Browse 500k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide\n",
      "## Relevant Links:\n",
      "\n",
      "\n",
      "### Link: about company\n",
      "Hugging Face â€“ The AI community building the future.\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 2M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "zai-org/GLM-Image\n",
      "Updated\n",
      "about 19 hours ago\n",
      "â€¢\n",
      "2.44k\n",
      "â€¢\n",
      "704\n",
      "fal/Qwen-Image-Edit-2511-Multiple-Angles-LoRA\n",
      "Updated\n",
      "8 days ago\n",
      "â€¢\n",
      "44.1k\n",
      "â€¢\n",
      "686\n",
      "Lightricks/LTX-2\n",
      "Updated\n",
      "1 day ago\n",
      "â€¢\n",
      "1.19M\n",
      "â€¢\n",
      "1.05k\n",
      "openbmb/AgentCPM-Explore\n",
      "Updated\n",
      "2 days ago\n",
      "â€¢\n",
      "315\n",
      "â€¢\n",
      "293\n",
      "Kijai/LTXV2_comfy\n",
      "Updated\n",
      "1 day ago\n",
      "â€¢\n",
      "41.1k\n",
      "â€¢\n",
      "283\n",
      "Browse 2M+ models\n",
      "Spaces\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "Featured\n",
      "798\n",
      "Qwen Image Multiple Angles 3D Camera\n",
      "ðŸŽ¥\n",
      "798\n",
      "Adjust camera angles in images using 3D controls or sliders\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "1.48k\n",
      "Z Image Turbo\n",
      "ðŸ–¼\n",
      "1.48k\n",
      "Generate stunning images from text descriptions in seconds\n",
      "Running\n",
      "Featured\n",
      "4.21k\n",
      "Wan2.2 Animate\n",
      "ðŸ‘\n",
      "4.21k\n",
      "Wan2.2 Animate\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "Featured\n",
      "395\n",
      "Qwen-Image-Edit-2511-LoRAs-Fast\n",
      "ðŸŽƒ\n",
      "395\n",
      "Demo of the Collection of Qwen Image Edit LoRAs\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "Featured\n",
      "1.83k\n",
      "Qwen Image Edit Camera Control\n",
      "ðŸŽ¬\n",
      "1.83k\n",
      "Fast 4 step inference with Qwen Image Edit 2509\n",
      "Browse 1M+ applications\n",
      "Datasets\n",
      "HuggingFaceFW/finetranslations\n",
      "Updated\n",
      "6 days ago\n",
      "â€¢\n",
      "14k\n",
      "â€¢\n",
      "204\n",
      "MiniMaxAI/OctoCodingBench\n",
      "Updated\n",
      "3 days ago\n",
      "â€¢\n",
      "2.64k\n",
      "â€¢\n",
      "183\n",
      "Alibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b\n",
      "Updated\n",
      "about 22 hours ago\n",
      "â€¢\n",
      "667\n",
      "â€¢\n",
      "113\n",
      "xiuhuywh/DRIM-VisualReasonHard\n",
      "Updated\n",
      "7 days ago\n",
      "â€¢\n",
      "1.95k\n",
      "â€¢\n",
      "127\n",
      "miromind-ai/MiroVerse-v0.1\n",
      "Updated\n",
      "about 3 hours ago\n",
      "â€¢\n",
      "810\n",
      "â€¢\n",
      "204\n",
      "Browse 500k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide\n",
      "\n",
      "### Link:  careers/jobs page\n",
      "Hugging Face - Current Openings\n",
      "\n",
      "\n",
      "\n",
      "### Link: enterprise/landing page\n",
      "Inference Endpoints by Hugging Face\n",
      "\n",
      "Inference\n",
      "Endpoints\n",
      "Catalog\n",
      "Log In\n",
      "Machine Learning At Your Service\n",
      "by\n",
      "Hugging Face\n",
      "Easily deploy your AI models to production on our fully managed platform. Instead of\n",
      "\t\t\t\tspending weeks configuring infrastructure, focus on building you AI application.\n",
      "Log In\n",
      "Learn More\n",
      "No Hugging Face account ?\n",
      "Sign up\n",
      "!\n",
      "One-click deployment\n",
      "Import your favorite model from Hugging Face or browse our catalog of hand-picked, ready-to-deploy models!\n",
      "ibm-granite /\n",
      "granite-3.3-8b-instruct-FP8\n",
      "17\n",
      "Deployed 17 times\n",
      "Text Generation\n",
      "vLLM\n",
      "Accelerated vLLM\n",
      "GPU\n",
      "1x Nvidia L40S\n",
      "$\n",
      "1.8\n",
      "openai /\n",
      "gpt-oss-safeguard-20b\n",
      "31\n",
      "Deployed 31 times\n",
      "Text Generation\n",
      "vLLM\n",
      "Accelerated vLLM\n",
      "GPU\n",
      "1x Nvidia L40S\n",
      "$\n",
      "1.8\n",
      "allenai /\n",
      "olmOCR-2-7B-1025-FP8\n",
      "44\n",
      "Deployed 44 times\n",
      "Image-Text-to-Text\n",
      "vLLM\n",
      "Accelerated vLLM\n",
      "GPU\n",
      "1x Nvidia L40S\n",
      "$\n",
      "1.8\n",
      "Qwen /\n",
      "Qwen3-VL-30B-A3B-Thinking\n",
      "36\n",
      "Deployed 36 times\n",
      "Image-Text-to-Text\n",
      "vLLM\n",
      "Accelerated vLLM\n",
      "GPU\n",
      "2x Nvidia A100\n",
      "$\n",
      "5\n",
      "Qwen /\n",
      "Qwen3-VL-8B-Instruct\n",
      "94\n",
      "Deployed 94 times\n",
      "Image-Text-to-Text\n",
      "vLLM\n",
      "Accelerated vLLM\n",
      "GPU\n",
      "1x Nvidia A100\n",
      "$\n",
      "2.5\n",
      "Browse Catalog\n",
      "Hub Models\n",
      "Trusted By\n",
      "These teams are running AI models on Inference Endpoints\n",
      "Features\n",
      "Everything you need to deploy AI models at scale\n",
      "Fully Managed Infrastructure\n",
      "Don't worry about Kubernetes, CUDA versions, or configuring VPNs. Focus on deploying your model and serving customers.\n",
      "Autoscaling\n",
      "Automatically scales up as traffic increases and down as it decreases to save on compute costs.\n",
      "Observability\n",
      "Understand and debug your model through comprehensive logs & metrics.\n",
      "Inference Engines\n",
      "Deploy with vLLM, TGI, SGLang, TEI, or custom containers.\n",
      "Hugging Face Integration\n",
      "Download model weights fast and securely with seamless Hugging Face Hub integration.\n",
      "Future-proof AI Stack\n",
      "Stay current with the latest frameworks and optimizations without managing complex upgrades.\n",
      "Pricing\n",
      "Choose a plan that fits your needs\n",
      "Self-Serve\n",
      "Pay as you go when using Inference Endpoints\n",
      "Pay for what you use, per minute\n",
      "Starting a\n",
      "\n",
      "### Link: github company page\n",
      "Hugging Face Â· GitHub\n",
      "\n",
      "Skip to content\n",
      "Navigation Menu\n",
      "Toggle navigation\n",
      "Sign in\n",
      "Appearance settings\n",
      "huggingface\n",
      "Platform\n",
      "AI CODE CREATION\n",
      "GitHub Copilot\n",
      "Write better code with AI\n",
      "GitHub Spark\n",
      "Build and deploy intelligent apps\n",
      "GitHub Models\n",
      "Manage and compare prompts\n",
      "MCP Registry\n",
      "New\n",
      "Integrate external tools\n",
      "DEVELOPER WORKFLOWS\n",
      "Actions\n",
      "Automate any workflow\n",
      "Codespaces\n",
      "Instant dev environments\n",
      "Issues\n",
      "Plan and track work\n",
      "Code Review\n",
      "Manage code changes\n",
      "APPLICATION SECURITY\n",
      "GitHub Advanced Security\n",
      "Find and fix vulnerabilities\n",
      "Code security\n",
      "Secure your code as you build\n",
      "Secret protection\n",
      "Stop leaks before they start\n",
      "EXPLORE\n",
      "Why GitHub\n",
      "Documentation\n",
      "Blog\n",
      "Changelog\n",
      "Marketplace\n",
      "View all features\n",
      "Solutions\n",
      "BY COMPANY SIZE\n",
      "Enterprises\n",
      "Small and medium teams\n",
      "Startups\n",
      "Nonprofits\n",
      "BY USE CASE\n",
      "App Modernization\n",
      "DevSecOps\n",
      "DevOps\n",
      "CI/CD\n",
      "View all use cases\n",
      "BY INDUSTRY\n",
      "Healthcare\n",
      "Financial services\n",
      "Manufacturing\n",
      "Government\n",
      "View all industries\n",
      "View all solutions\n",
      "Resources\n",
      "EXPLORE BY TOPIC\n",
      "AI\n",
      "Software Development\n",
      "DevOps\n",
      "Security\n",
      "View all topics\n",
      "EXPLORE BY TYPE\n",
      "Customer stories\n",
      "Events & webinars\n",
      "Ebooks & reports\n",
      "Business insights\n",
      "GitHub Skills\n",
      "SUPPORT & SERVICES\n",
      "Documentation\n",
      "Customer support\n",
      "Community forum\n",
      "Trust center\n",
      "Partners\n",
      "Open Source\n",
      "COMMUNITY\n",
      "GitHub Sponsors\n",
      "Fund open source developers\n",
      "PROGRAMS\n",
      "Security Lab\n",
      "Maintainer Community\n",
      "Accelerator\n",
      "Archive Program\n",
      "REPOSITORIES\n",
      "Topics\n",
      "Trending\n",
      "Collections\n",
      "Enterprise\n",
      "ENTERPRISE SOLUTIONS\n",
      "Enterprise platform\n",
      "AI-powered developer platform\n",
      "AVAILABLE ADD-ONS\n",
      "GitHub Advanced Security\n",
      "Enterprise-grade security features\n",
      "Copilot for Business\n",
      "Enterprise-grade AI features\n",
      "Premium Support\n",
      "Enterprise-grade 24/7 support\n",
      "Pricing\n",
      "Search or jump to...\n",
      "Search code, repositories, users, issues, pull requests...\n",
      "Search\n",
      "Clear\n",
      "Search syntax tips\n",
      "Provide feedback\n",
      "We read every piece of feedback, and take your input very seriously.\n",
      "Include my email address so I can be contacted\n",
      "Cancel\n",
      "Submit feedback\n",
      "Saved searches\n",
      "Use saved searches to filter your results more\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "9b863a55-f86c-4e3f-8a79-94e24c1a8cf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:41:59.323656Z",
     "start_time": "2026-01-16T04:41:59.316490Z"
    }
   },
   "source": [
    "brochure_system_prompt = \"\"\"\n",
    "You are an assistant that analyzes the contents of several relevant pages from a company website\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits.\n",
    "Respond in markdown without code blocks.\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\n",
    "\"\"\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# brochure_system_prompt = \"\"\"\n",
    "# You are an assistant that analyzes the contents of several relevant pages from a company website\n",
    "# and creates a short, humorous, entertaining, witty brochure about the company for prospective customers, investors and recruits.\n",
    "# Respond in markdown without code blocks.\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\n",
    "# \"\"\"\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "6ab83d92-d36b-4ce0-8bcc-5bb4c2f8ff23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:42:01.380069Z",
     "start_time": "2026-01-16T04:42:01.373171Z"
    }
   },
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"\"\"\n",
    "You are looking at a company called: {company_name}\n",
    "Here are the contents of its landing page and other relevant pages;\n",
    "use this information to build a short brochure of the company in markdown without code blocks.\\n\\n\n",
    "\"\"\"\n",
    "    user_prompt += fetch_page_and_all_relevant_links(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "cd909e0b-1312-4ce2-a553-821e795d7572",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:42:32.636106Z",
     "start_time": "2026-01-16T04:42:05.877377Z"
    }
   },
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting relevant links for https://huggingface.co by calling llama3.2:latest\n",
      "Found 10 relevant links\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='blog.huggingface.co', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"HTTPSConnection(host='blog.huggingface.co', port=443): Failed to resolve 'blog.huggingface.co' ([Errno 8] nodename nor servname provided, or not known)\"))",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mgaierror\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/urllib3/connection.py:204\u001B[39m, in \u001B[36mHTTPConnection._new_conn\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    203\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m204\u001B[39m     sock = \u001B[43mconnection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate_connection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    205\u001B[39m \u001B[43m        \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dns_host\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    206\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    207\u001B[39m \u001B[43m        \u001B[49m\u001B[43msource_address\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msource_address\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    208\u001B[39m \u001B[43m        \u001B[49m\u001B[43msocket_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msocket_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    209\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    210\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m socket.gaierror \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/urllib3/util/connection.py:60\u001B[39m, in \u001B[36mcreate_connection\u001B[39m\u001B[34m(address, timeout, source_address, socket_options)\u001B[39m\n\u001B[32m     58\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m LocationParseError(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhost\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m, label empty or too long\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m60\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m \u001B[43msocket\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgetaddrinfo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mport\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfamily\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msocket\u001B[49m\u001B[43m.\u001B[49m\u001B[43mSOCK_STREAM\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m     61\u001B[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/socket.py:974\u001B[39m, in \u001B[36mgetaddrinfo\u001B[39m\u001B[34m(host, port, family, type, proto, flags)\u001B[39m\n\u001B[32m    973\u001B[39m addrlist = []\n\u001B[32m--> \u001B[39m\u001B[32m974\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m \u001B[43m_socket\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgetaddrinfo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mport\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfamily\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproto\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m    975\u001B[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001B[31mgaierror\u001B[39m: [Errno 8] nodename nor servname provided, or not known",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mNameResolutionError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001B[39m, in \u001B[36mHTTPConnectionPool.urlopen\u001B[39m\u001B[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[39m\n\u001B[32m    786\u001B[39m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m787\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    788\u001B[39m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    789\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    790\u001B[39m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    791\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    792\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    793\u001B[39m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    794\u001B[39m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[43m=\u001B[49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    795\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    796\u001B[39m \u001B[43m    \u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    797\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    798\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    799\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mresponse_kw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    800\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    802\u001B[39m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/urllib3/connectionpool.py:488\u001B[39m, in \u001B[36mHTTPConnectionPool._make_request\u001B[39m\u001B[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[39m\n\u001B[32m    487\u001B[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n\u001B[32m--> \u001B[39m\u001B[32m488\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m new_e\n\u001B[32m    490\u001B[39m \u001B[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001B[39;00m\n\u001B[32m    491\u001B[39m \u001B[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/urllib3/connectionpool.py:464\u001B[39m, in \u001B[36mHTTPConnectionPool._make_request\u001B[39m\u001B[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[39m\n\u001B[32m    463\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m464\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_validate_conn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    465\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError) \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/urllib3/connectionpool.py:1093\u001B[39m, in \u001B[36mHTTPSConnectionPool._validate_conn\u001B[39m\u001B[34m(self, conn)\u001B[39m\n\u001B[32m   1092\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m conn.is_closed:\n\u001B[32m-> \u001B[39m\u001B[32m1093\u001B[39m     \u001B[43mconn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1095\u001B[39m \u001B[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/urllib3/connection.py:759\u001B[39m, in \u001B[36mHTTPSConnection.connect\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    758\u001B[39m sock: socket.socket | ssl.SSLSocket\n\u001B[32m--> \u001B[39m\u001B[32m759\u001B[39m \u001B[38;5;28mself\u001B[39m.sock = sock = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_new_conn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    760\u001B[39m server_hostname: \u001B[38;5;28mstr\u001B[39m = \u001B[38;5;28mself\u001B[39m.host\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/urllib3/connection.py:211\u001B[39m, in \u001B[36mHTTPConnection._new_conn\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    210\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m socket.gaierror \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m--> \u001B[39m\u001B[32m211\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m NameResolutionError(\u001B[38;5;28mself\u001B[39m.host, \u001B[38;5;28mself\u001B[39m, e) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n\u001B[32m    212\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m SocketTimeout \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[31mNameResolutionError\u001B[39m: HTTPSConnection(host='blog.huggingface.co', port=443): Failed to resolve 'blog.huggingface.co' ([Errno 8] nodename nor servname provided, or not known)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mMaxRetryError\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/requests/adapters.py:644\u001B[39m, in \u001B[36mHTTPAdapter.send\u001B[39m\u001B[34m(self, request, stream, timeout, verify, cert, proxies)\u001B[39m\n\u001B[32m    643\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m644\u001B[39m     resp = \u001B[43mconn\u001B[49m\u001B[43m.\u001B[49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    645\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    646\u001B[39m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m=\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    647\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    648\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m.\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    650\u001B[39m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    651\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    652\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    653\u001B[39m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    654\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    655\u001B[39m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[43m=\u001B[49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    656\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    658\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/urllib3/connectionpool.py:841\u001B[39m, in \u001B[36mHTTPConnectionPool.urlopen\u001B[39m\u001B[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[39m\n\u001B[32m    839\u001B[39m     new_e = ProtocolError(\u001B[33m\"\u001B[39m\u001B[33mConnection aborted.\u001B[39m\u001B[33m\"\u001B[39m, new_e)\n\u001B[32m--> \u001B[39m\u001B[32m841\u001B[39m retries = \u001B[43mretries\u001B[49m\u001B[43m.\u001B[49m\u001B[43mincrement\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    842\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnew_e\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pool\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacktrace\u001B[49m\u001B[43m=\u001B[49m\u001B[43msys\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexc_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[32m    843\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    844\u001B[39m retries.sleep()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/urllib3/util/retry.py:535\u001B[39m, in \u001B[36mRetry.increment\u001B[39m\u001B[34m(self, method, url, response, error, _pool, _stacktrace)\u001B[39m\n\u001B[32m    534\u001B[39m     reason = error \u001B[38;5;129;01mor\u001B[39;00m ResponseError(cause)\n\u001B[32m--> \u001B[39m\u001B[32m535\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m MaxRetryError(_pool, url, reason) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mreason\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[32m    537\u001B[39m log.debug(\u001B[33m\"\u001B[39m\u001B[33mIncremented Retry for (url=\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m): \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[33m\"\u001B[39m, url, new_retry)\n",
      "\u001B[31mMaxRetryError\u001B[39m: HTTPSConnectionPool(host='blog.huggingface.co', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"HTTPSConnection(host='blog.huggingface.co', port=443): Failed to resolve 'blog.huggingface.co' ([Errno 8] nodename nor servname provided, or not known)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mConnectionError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mget_brochure_user_prompt\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mHuggingFace\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mhttps://huggingface.co\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[28]\u001B[39m\u001B[32m, line 7\u001B[39m, in \u001B[36mget_brochure_user_prompt\u001B[39m\u001B[34m(company_name, url)\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_brochure_user_prompt\u001B[39m(company_name, url):\n\u001B[32m      2\u001B[39m     user_prompt = \u001B[33mf\u001B[39m\u001B[33m\"\"\"\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[33mYou are looking at a company called: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcompany_name\u001B[38;5;132;01m}\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[33mHere are the contents of its landing page and other relevant pages;\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[33muse this information to build a short brochure of the company in markdown without code blocks.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\n\u001B[32m      6\u001B[39m \u001B[33m\"\"\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m     user_prompt += \u001B[43mfetch_page_and_all_relevant_links\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      8\u001B[39m     user_prompt = user_prompt[:\u001B[32m5_000\u001B[39m] \u001B[38;5;66;03m# Truncate if more than 5,000 characters\u001B[39;00m\n\u001B[32m      9\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m user_prompt\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[24]\u001B[39m\u001B[32m, line 7\u001B[39m, in \u001B[36mfetch_page_and_all_relevant_links\u001B[39m\u001B[34m(url)\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m link \u001B[38;5;129;01min\u001B[39;00m relevant_links[\u001B[33m'\u001B[39m\u001B[33mlinks\u001B[39m\u001B[33m'\u001B[39m]:\n\u001B[32m      6\u001B[39m     result += \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m### Link: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlink[\u001B[33m'\u001B[39m\u001B[33mtype\u001B[39m\u001B[33m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m     result += \u001B[43mfetch_website_contents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlink\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43murl\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal/Code/Python/llm_engineering/week1/scraper.py:16\u001B[39m, in \u001B[36mfetch_website_contents\u001B[39m\u001B[34m(url)\u001B[39m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfetch_website_contents\u001B[39m(url):\n\u001B[32m     12\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[33;03m    Return the title and contents of the website at the given url;\u001B[39;00m\n\u001B[32m     14\u001B[39m \u001B[33;03m    truncate to 2,000 characters as a sensible limit\u001B[39;00m\n\u001B[32m     15\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m     response = \u001B[43mrequests\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m     soup = BeautifulSoup(response.content, \u001B[33m\"\u001B[39m\u001B[33mhtml.parser\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     18\u001B[39m     title = soup.title.string \u001B[38;5;28;01mif\u001B[39;00m soup.title \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mNo title found\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/requests/api.py:73\u001B[39m, in \u001B[36mget\u001B[39m\u001B[34m(url, params, **kwargs)\u001B[39m\n\u001B[32m     62\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget\u001B[39m(url, params=\u001B[38;5;28;01mNone\u001B[39;00m, **kwargs):\n\u001B[32m     63\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[32m     64\u001B[39m \n\u001B[32m     65\u001B[39m \u001B[33;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     70\u001B[39m \u001B[33;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[32m     71\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m73\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mget\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/requests/api.py:59\u001B[39m, in \u001B[36mrequest\u001B[39m\u001B[34m(method, url, **kwargs)\u001B[39m\n\u001B[32m     55\u001B[39m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[32m     56\u001B[39m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[32m     57\u001B[39m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m sessions.Session() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m=\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/requests/sessions.py:589\u001B[39m, in \u001B[36mSession.request\u001B[39m\u001B[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[39m\n\u001B[32m    584\u001B[39m send_kwargs = {\n\u001B[32m    585\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtimeout\u001B[39m\u001B[33m\"\u001B[39m: timeout,\n\u001B[32m    586\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mallow_redirects\u001B[39m\u001B[33m\"\u001B[39m: allow_redirects,\n\u001B[32m    587\u001B[39m }\n\u001B[32m    588\u001B[39m send_kwargs.update(settings)\n\u001B[32m--> \u001B[39m\u001B[32m589\u001B[39m resp = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    591\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/requests/sessions.py:703\u001B[39m, in \u001B[36mSession.send\u001B[39m\u001B[34m(self, request, **kwargs)\u001B[39m\n\u001B[32m    700\u001B[39m start = preferred_clock()\n\u001B[32m    702\u001B[39m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m703\u001B[39m r = \u001B[43madapter\u001B[49m\u001B[43m.\u001B[49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    705\u001B[39m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[32m    706\u001B[39m elapsed = preferred_clock() - start\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/llm_engineering/lib/python3.11/site-packages/requests/adapters.py:677\u001B[39m, in \u001B[36mHTTPAdapter.send\u001B[39m\u001B[34m(self, request, stream, timeout, verify, cert, proxies)\u001B[39m\n\u001B[32m    673\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e.reason, _SSLError):\n\u001B[32m    674\u001B[39m         \u001B[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001B[39;00m\n\u001B[32m    675\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m SSLError(e, request=request)\n\u001B[32m--> \u001B[39m\u001B[32m677\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(e, request=request)\n\u001B[32m    679\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m ClosedPoolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    680\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(e, request=request)\n",
      "\u001B[31mConnectionError\u001B[39m: HTTPSConnectionPool(host='blog.huggingface.co', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"HTTPSConnection(host='blog.huggingface.co', port=443): Failed to resolve 'blog.huggingface.co' ([Errno 8] nodename nor servname provided, or not known)\"))"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "8b45846d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:19:26.114911Z",
     "start_time": "2026-01-16T04:19:26.081650Z"
    }
   },
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "b123615a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:20:08.207038Z",
     "start_time": "2026-01-16T04:19:34.823347Z"
    }
   },
   "source": [
    "create_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting relevant links for https://huggingface.co by calling gpt-5-nano\n",
      "Found 12 relevant links\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "# Hugging Face: Building the Future of AI Together\n\n---\n\n## Who We Are\n\nHugging Face is the leading AI community and collaboration platform dedicated to advancing machine learning. We provide a dynamic hub where researchers, engineers, and enthusiasts come together to create, share, and deploy cutting-edge machine learning models, datasets, and applications. Our mission is to empower the next generation of machine learning professionals to build an open, collaborative, and ethical AI future.\n\n---\n\n## What We Offer\n\n- **2 Million+ Models:** Explore, use, and contribute to one of the worldâ€™s largest collections of open-source machine learning models across all data modalities including text, image, video, audio, and even 3D.\n\n- **500,000+ Datasets:** Access an enormous variety of public datasets that fuel advanced AI model training and research.\n\n- **1 Million+ Applications:** Discover AI-powered applications built by the community and personalize your exploration of AI innovations.\n\n- **Spaces:** Host and interact with machine learning applications in a zero-setup environment, allowing rapid experimentation and sharing.\n\n- **HF Open Source Stack:** Leverage a robust and fast open-source toolkit to accelerate your ML development cycle.\n\n---\n\n## Our Community\n\nHugging Face thrives on its vibrant global community of machine learning practitioners, researchers, and developers. We foster a collaborative culture that values:\n\n- **Open Innovation:** Everyone can share their models, datasets, and applications for free, contributing to collective progress.\n\n- **Ethical AI:** Commitment to building AI tools that are transparent, fair, and responsibly developed.\n\n- **Learning & Growth:** Providing resources and a platform to build your personal ML portfolio and reputation.\n\n- **Diversity & Inclusion:** Encouraging participation from diverse backgrounds to enrich the AI ecosystem.\n\n---\n\n## For Customers & Enterprise\n\nWe support organizations in scaling their AI initiatives with enterprise-grade solutions and dedicated support while maintaining the spirit of openness and collaboration. Whether youâ€™re building next-gen products or conducting research, Hugging Face offers the tools to accelerate your machine learning roadmap.\n\n---\n\n## Careers at Hugging Face\n\nJoin a passionate team shaping the future of machine learning! We offer opportunities for engineers, researchers, product managers, and community builders eager to work in a fast-paced environment that values creativity, impact, and open collaboration. Be part of an innovative culture dedicated to ethical AI and global community building.\n\n---\n\n## Get Involved\n\n- Explore AI models and apps at [huggingface.co](https://huggingface.co)\n- Sign up to contribute and build your ML profile.\n- Engage with our growing community through forums and collaborative projects.\n- Access full documentation and developer tools.\n\n---\n\n## Brand & Identity\n\nHugging Face represents openness and creativity in AI:\n\n- Primary colors: Yellow (#FFD21E, #FF9D00) and Gray (#6B7280)\n- Branding assets including logos are available to promote our values and identity.\n\n---\n\n*Hugging Face: The Home of Machine Learning Collaboration*  \nTogether, we move AI forward. Join us!"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "61eaaab7-0b47-4b29-82d4-75d474ad8d18",
   "metadata": {},
   "source": [
    "## Finally - a minor improvement\n",
    "\n",
    "With a small adjustment, we can change this so that the results stream back from OpenAI,\n",
    "with the familiar typewriter animation"
   ]
  },
  {
   "cell_type": "code",
   "id": "51db0e49-f261-4137-aabe-92dd601f7725",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:20:28.505337Z",
     "start_time": "2026-01-16T04:20:28.483772Z"
    }
   },
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "56bf0ae3-ee9d-4a72-9cd6-edcac67ceb6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T04:21:16.915326Z",
     "start_time": "2026-01-16T04:20:31.233881Z"
    }
   },
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting relevant links for https://huggingface.co by calling gpt-5-nano\n",
      "Found 11 relevant links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "# Hugging Face Brochure\n\n---\n\n## About Hugging Face\n\n**Hugging Face** is the leading AI community and platform dedicated to building the future of machine learning. It empowers a global community of developers, researchers, and enterprises to discover, create, share, and collaborate on machine learning models, datasets, and applications.  \n\nWith over **2 million models**, and hundreds of thousands of datasets and applications, Hugging Face covers a wide spectrum of AI modalities including text, image, video, audio, and even 3D. It is not just a platform but a vibrant community where machine learning practitioners grow their skills, share projects, and build professional portfolios.\n\n---\n\n## What Hugging Face Offers\n\n- **Models:** Access and contribute to over 2 million pre-trained AI models.\n- **Datasets:** Browse and host more than 500,000 datasets.\n- **Spaces:** Deploy interactive machine learning applications with ease.\n- **Community:** Engage with AI enthusiasts, experts, and collaborators worldwide.\n- **Open Source Stack:** Utilize powerful open-source tools to accelerate ML development.\n- **Multi-Modal Support:** Work with diverse data typesâ€”text, image, video, audio, and 3D.\n\n---\n\n## For Enterprises & Teams\n\nHugging Face offers tailored solutions for organizations looking to scale AI initiatives securely and efficiently:\n\n- **Team & Enterprise Plans:** Starting at $20 per user/month, or customized enterprise contracts.\n- **Enterprise-Grade Security:** Single Sign-On (SSO), advanced security policies, detailed audit logs.\n- **Private Storage & Data Management:** 1 TB private storage per user plus options for additional storage.\n- **Granular Access Control:** Resource groups and centralized token management.\n- **Advanced Compute:** Access to ZeroGPU and options to boost quotas by 5Ã—.\n- **Billing & Analytics:** Manage budgets, monitor usage, and get detailed analytics through a unified dashboard.\n- **Priority Support:** Enterprise customers receive dedicated priority support.\n\n---\n\n## Pricing Highlights\n\n- **Free Tier:** Community access to models, datasets, spaces, and collaboration tools.\n- **Pro Plan ($9/month):** Enhanced features for individuals including:\n  - 10Ã— private storage capacity\n  - 20Ã— inference credits\n  - 8Ã— ZeroGPU quota and higher queue priority\n  - Spaces Dev Mode & ZeroGPU hosting\n  - Ability to publish blog articles on HF profile\n- **Team Plan ($20/user/month):** Onboarding for teams with features like SSO and enterprise integrations.\n\n---\n\n## Company Culture\n\nHugging Face fosters an open, collaborative, and inclusive culture where innovation and sharing thrive. Being community-driven, it enables contributors worldwide to build knowledge, share breakthroughs, and accelerate AI researches and applications together.\n\n- **Community-Centric:** The core of Hugging Face is its vibrant, global AI community.\n- **Open Source Enthusiasts:** Heavy investment in open source AI tools and resources.\n- **Innovation & Accessibility:** Committed to making cutting-edge AI technology accessible to all.\n- **Developer Friendly:** Building tools and platforms that empower machine learning practitioners at every level.\n\n---\n\n## Careers at Hugging Face\n\nHugging Face is continuously growing and welcomes talented individuals passionate about advancing AI technology. Career opportunities include roles in:\n\n- Machine Learning Research and Engineering\n- Software Development and Platform Engineering\n- Customer Success and Enterprise Solutions\n- Community Management and Developer Relations\n\nWorking at Hugging Face means contributing to a future where AI is more collaborative, transparent, and impactful globally.\n\n---\n\n## Join Hugging Face\n\nWhether you are an AI researcher, developer, enterprise leader, or enthusiast, Hugging Face invites you to:\n\n- **Explore and build** with state-of-the-art models and datasets\n- **Deploy** AI applications easily on the community-driven Spaces platform\n- **Collaborate** with leading scientists and engineers\n- **Scale** AI solutions securely in your organization with enterprise features\n\n**Sign up today** and become part of the AI community building the future.\n\n---\n\n### Website: [huggingface.co](https://huggingface.co)  \n### Contact: enterprise@huggingface.co (for sales and enterprise inquiries)  \n### Pricing & Plans: [huggingface.co/pricing](https://huggingface.co/pricing)\n\n---\n\n*Hugging Face â€“ The AI community building the future.*"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "3ff4cf24fe2daccc60c2931558d066c6"
     }
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb3f8d8-a3eb-41c8-b1aa-9f60686a653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try changing the system prompt to the humorous version when you make the Brochure for Hugging Face:\n",
    "\n",
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bf9e0-665f-4645-b66b-9725e2a959b5",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise we extended the Day 1 code to make multiple LLM calls, and generate a document.\n",
    "\n",
    "This is perhaps the first example of Agentic AI design patterns, as we combined multiple calls to LLMs. This will feature more in Week 2, and then we will return to Agentic AI in a big way in Week 8 when we build a fully autonomous Agent solution.\n",
    "\n",
    "Generating content in this way is one of the very most common Use Cases. As with summarization, this can be applied to any business vertical. Write marketing content, generate a product tutorial from a spec, create personalized email content, and so much more. Explore how you can apply content generation to your business, and try making yourself a proof-of-concept prototype. See what other students have done in the community-contributions folder -- so many valuable projects -- it's wild!</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2454b-8ef8-4b5c-b928-053a15e0d553",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you move to Week 2 (which is tons of fun)</h2>\n",
    "            <span style=\"color:#900;\">Please see the week1 EXERCISE notebook for your challenge for the end of week 1. This will give you some essential practice working with Frontier APIs, and prepare you well for Week 2.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b64f0f-7d33-4493-985a-033d06e8db08",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">A reminder on 3 useful resources</h2>\n",
    "            <span style=\"color:#f71;\">1. The resources for the course are available <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">here.</a><br/>\n",
    "            2. I'm on LinkedIn <a href=\"https://www.linkedin.com/in/eddonner/\">here</a> and I love connecting with people taking the course!<br/>\n",
    "            3. I'm trying out X/Twitter and I'm at <a href=\"https://x.com/edwarddonner\">@edwarddonner<a> and hoping people will teach me how it's done..  \n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48e42e-fa7a-495f-a5d4-26bfc24d60b6",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/thankyou.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#090;\">Finally! I have a special request for you</h2>\n",
    "            <span style=\"color:#090;\">\n",
    "                My editor tells me that it makes a MASSIVE difference when students rate this course on Udemy - it's one of the main ways that Udemy decides whether to show it to others. If you're able to take a minute to rate this, I'd be so very grateful! And regardless - always please reach out to me at ed@edwarddonner.com if I can help at any point.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
